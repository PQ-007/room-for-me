---
draft: false
language:
  - mn
tags:
  - Book/DeapLearning2
date: 2026-01-28
---
## Математик болон Python-ны бататгал

>ひとつ以上の方法を知るまでは、ものごとを理解したことにはならない。
―― マービン・ミンスキー（コンピュータ科学者、認知科学者）

>Нэгээс олон аргад суралцахгүй бол аливааг бүтэн ойлгохгүй.
>―― Марвин Мински (Компьютерын шинжлэх ухаанч, танин мэдэхүйн шинжлэх ухаанч)
### Вектор ба Матриц

Вектор бол хэмжээ болон чиглэлтэй байдаг хэмжигдэхүүн гэж бид заалгадаг. Скаляр нь харин чиглэлгүй энгийн тоо гэх мэтээр.  Гэвч бидний энд өгүүлэх вектор, матриц (цааш өргөтгөвөл тенсор) нь зүгээр л өгөгдлийг хадгалах, тооцоолох зориулалттай **сав** юм.

> 0D, 1D, 2D, 3D массивуудыг бид өөрсдийнх нь нэрээр (скаляр, вектор, матриц) нэрлээд заншчихсан. Харин 4D болон түүнээс дээш хэмжээстэй массивуудад тусгай нэр байхгүй учраас шууд **Тензор** гэж ерөнхийлөн нэрлэдэг.

```python
>>> import numpy as np
>>> x = np.array([1, 2, 3])
>>> x.__class__ # クラス名を表示
<class 'numpy.ndarray'>
>>> x.shape
(3,)
>>> x.ndim
1
>>> W = np.array([[1, 2, 3], [4, 5, 6]])
>>> W.shape
(2, 3)
>>> W.ndim
2
```

### Матрицын элемент дээрх үйлдлүүд

>要素ごとの」とは英語で element-wise と言います。

```python
>>> W = np.array([[1, 2, 3], [4, 5, 6]])
>>> X = np.array([[0, 1, 2], [3, 4, 5]])
>>> W + X
array([[ 1, 3, 5],
[ 7, 9, 11]])
>>> W * X
array([[ 0, 2, 6],
[12, 20, 30]])
```

**Нэмж хасах үржиж хуваах үйлдлүүдийг хийхдээ зөвхөн харгалзах элемент / утгууд дээр шууд хийдэг.**

### Броадкастинг

Хоорондоо ижил хэмжээст биш матрицууд дээр ч гэсэн аритметик үйлдлүүд хийж чадна. 2 х 2 хэмжээст матрицыг 10 гэх скаляр утгаар үржүүлснийг доор үзүүлэв. Ерөнхий тогтмол тоогоор гишүүн бүрийг үржүүлж байгаа хэрэг.

```python
>>> A = np.array([[1, 2], [3, 4]])
>>> A * 10
array([[10, 20],
[30, 40]])
```

![[Pasted image 20260128185536.png]]

Энэ мэтээр математик дээр бидний хийдэг матриц дээрх үйдлүүдийг numpy сан нөхөж өргөтгөн харгалзан үйлдлийг гүйцэтгэх байдлаар хийдэг. 

 >**Broadcasting** гэдэг нь хэмжээ нь зөрүүтэй массивуудын хооронд үйлдэл хийхдээ, жижиг хэмжээсийг дүрмийн дагуу “сунгаж тааруулсан” гэж үзээд элемент-wise үйлдлийг гүйцэтгэх арга юм. Ингэснээр хэрэглэгч давталт бичихгүй, NumPy дотроо оновчтойгаар тооцооллыг хийдэг. .

**Дүрэм:** 
 **Хэмжээсийг баруунаас нь тааруулж харна. Хэрвээ хэмжээс бүр дээр “ижил” эсвэл “1” байвал broadcasting боломжтой.** 

### Вектор үржвэр ба Матриц үржвэр

$$\underbrace{x \cdot y}_{\text{Dot Product}} = \sum_{i=1}^{n} x_i y_i \tag{1}$$

>Дотоод үржвэр (dot product) нь хоёр вектор “хэр адил чиглэлтэй вэ” гэдгийг тоогоор илэрхийлдэг.  
>Хэрвээ хоёр векторын уртыг 1 болгож нормалчилбал (unit vector), үр дүн нь **cos(θ)** болж, ижил чиглэлд 1, эсрэг чиглэлд -1, перпендикуляр үед 0 болно.

```python
# ベクトルの内積
>>> a = np.array([1, 2, 3])
>>> b = np.array([4, 5, 6])
>>> np.dot(a, b)
32
# 行列の積
>>> A = np.array([[1, 2], [3, 4]])
>>> B = np.array([[5, 6], [7, 8]])
>>> np.dot(A, B)
array([[19, 22],
[43, 50]])
```

 Вектор үржвэр ч бай Матриц үржвэр ч бай `numpy.dot()` гэдэг функц ашиглан олж болно.

```python
A * B        # element-wise (энгийн үржих зөвхөн харгалзах элементүүдэд)
A @ B        # @ нь матриц / вектор үржвэрийн оператор
A.dot(B)    # матриц үржвэр / векторын хувьд вектор үржвэр
```

### Матрицын хэмжээсийг шалгах

Матрицуудыг үржүүлэхийн тулд эхний матрицын баганын тоо нь дараагийн матрицын мөрийн тоотой заавал тэнцүү байх ёстой. Үүнийг урьдчилан шалгахыг матрицын хэлбэр (shape) шалгалт гэнэ.

> Мөр–багана таарахгүй бол матрицын үржвэр боломжгүй. Тоо дутна.

$$
(m \times \underbrace{n)\,(n}_{\text{Тэнцүү}} \times k)
\;\longrightarrow\;
(m \times k)
$$
## Нейрон сүлжээний тухай

 Энэ бол ердөө л нэг функц. Нэг юм оруулна, дараа нь өөр нэг юм гаргана. Энгийнээр хувиргалт хийх хэрэгсэл. 

Гэхдээ миний ажигласнаар ямар нэгэн ажилд, эсвэл даалгаварт зориулж (оролтын утгыг гаралтын үр дүнд хувиргах явцад нь нөлөөлснөөр) хувисгаж өөрчлөн, тохируулж болдог нь энэхүү аргын гол хүч, онцлог нь юм шиг санагдсан.  

Нейрон сүлжээ нь олон параметртэй. Оролт $x$-ийг авч, параметрүүд $W$ (weight), $b$ (bias)-ийн дагуу гаралт $y$ болгоно.  

>**Сургалт** (training) гэдэг нь эдгээр параметрүүдийг даалгаварт тааруулж өөрчилж тохируулах үйл явц.

![[Drawing 2026-02-02 12.14.23.excalidraw.png]]

Бүтцийн хувьд оролтын, нуугдмал, гаралтын гэсэн давхаргуудтай. Давхарга (оролтын давхаргаас бусад) бүр нь “шугаман хувиргалт + идэвхжүүлэгч функц” гэсэн жижиг функцүүдийн цуваа гэж ойлгож болно.

### Шугаман хувиргалтын тэгшитгэл:
$$h_1 = x_1w_{11} + x_2w_{21} + b_1$$
Энэхүү тэгшитгэлийг олон нейрон тус бүр дээр бодолгүй дараах байдлаар нэгтгэн матрицын үржвэрээр илэрхийлж, тооцоолж болдог.

$$[h_1, h_2, h_3, h_4] = [x_1, x_2] 
\begin{bmatrix}
w_{11} & w_{12} & w_{13} & w_{14} \\
w_{21} & w_{22} & w_{23} & w_{24}
\end{bmatrix} 
+ [b_1, b_2, b_3, b_4]$$
Эдгээрийг хялбарчилбал: $\color{orange} h = xW + b$ болно. Дараах байдлаар numpy ашиглан python дээр энэхүү тэгшитгэлийн тооцоололлыг явуулдаг.

```python
>>> import numpy as np
>>> W1 = np.random.randn(2, 4) # weight
>>> b1 = np.random.randn(4) # bias
>>> x = np.random.randn(10, 2) # input
>>> h = np.dot(x, W1) + b1
```

### Идэвхжүүлэгч функц

Персептроноос нейрон сүлжээ болоход нь идэвхжүүлэгч функц л хэрэгтэй. Хэрвээ энэ байхгүй бол зүгээр л шугаман хувиргалт л болно. Олон давхарга байх хэрэггүй, үүнийг бүрэн ашиглахгүй гэсэн үг. Давхарга бүр нэг л үйдлээ хийдэг байна. Жишээлбэл өөр өөр давхарга өөр өөр идэвхжүүлэгч функцтэй байснаар нэг нь оролтын утгуудыг тогтворжуулж бага тооны интервалд хуваарьлах бол нөгөө нь гаралтын утгыг сургалтанд хэрэгтэй  байдлаар процентлох гэх мэтээр байж болдог.

## Нейрон сүлжээний сургалт

### Алдааны функц

Сургалтын явцад хэр зэрэг сайн сурч байна вэ? хэр зэрэг алдаж байна вэ? гэдгийн хэмжих параметр хэрэгтэй. Үүнийг алдаа гэх ба тестийн датаг нейрон сүлжээгээр гүйлгэн ажиллуулж зөв хариултаас хэр зэрэг алдаж байгааг илэрхийлэх хэмжээс юм. 
Алдааг олохын тулд алдааны функц ашиглана. Олон класст ангиллах даалгаврын хувьд алдааны функц болгож **Cross Entropy Error** функцыг ашигладаг. 

$$y_k=\frac{\exp(s_k)}{\sum\limits_{i=1}^n\exp(s_i)}$$$$L=-\sum_kt_k\log y_k$$