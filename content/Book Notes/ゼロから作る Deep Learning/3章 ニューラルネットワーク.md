***Perceptron  ашиглахад***:
- **Олон давхаргатай perceptron**-оор хэцүү бүтэц бүхий тооцооллын урсгалыг загварчилж болно.
- Гэвч **weight, bias** зэрэг параметрүүдийг нь зөв тохируулж өгөх хэрэгтэй.

> **Чухамдаа машин сургах гэж эдгээр параметрийг тохируулах тухай л зүйл.**

Гараар, хүний оролцоотой тохируулж ирсэн бол одоо энэхүү процессыг автоматжуулах хэрэг гарч ирэх бөгөөд нейрон сүлжээ нь үүний шийдэл юм. Тохирох жингийн параметрийг өгөгдөл дотроос өөрөө сурч чадах нь нейрон сүлжээний чухал шинж.

Энэ бүлэгт нейрон сүлжээний үндсэн агуулга, түүний ялган таних үйл явц өрнүүлэх үеийн боловсруулалтын тухай голчлон авч үзнэ. 

## パーセプトロンからニューラルネットワークへ

Нейрон сүлжээ нь өмнө бүлэгт өгүүлсэн Perceptron-тай олон талаараа ижил. 

### ニューラルネットワークの例

Доорх зурагт нейрон сүлжээний жишээг харуулсан байна. Оролтын давхарга, дунд байрлах давхарга (далд давхарга), гаралтын давхарга гэсэн хэсгүүдтэй. Далд давхаргад нейрон нь оролтын болон гаралтын давхаргаас ялгаатай нь харагдахгүй учир ингэж нэрлэсэн. 

![[Neural Network Example.png]]

Хэлбэрийн хувьд нейронуудыг давхарлаж холбосон учир Perceptron-той ижил харагдана.

### パーセプトロンの復習

![[Perceptron Example.png]]
$$
y = \begin{cases}
    0 & (b+w_1 x_1 + w_2 x_2 \leq 0) \\
    1 & (b+w_1 x_1 + w_2 x_2 > 0)
\end{cases}
$$
Perceptron нь дээрх тэгшитгэлийн дагуу ажилладаг. 
Энд $b$ нь bias, $w_1、w_2$ нь жин, $x_1、x_2$ нь оролтын утгууд. Жишээ зурагт bias-ийг дүрсэлж харуулаагүй бөгөөд дараах байдлаар нэмж болно. Яагаад нэг оролтын нейрон нэмж 1 гэж тэмдэглэж байгаа вэ гэвэл сургалт эхлээгүй байхад $b$ = 1  гэж үздэг учраас 1 ээр төлөөлүүлж, цааш сурах явцдаа тохируулж болохуйц хувьсагч гэдгийг нь илэрхийлэх үүднээс $b$ нь жин шиг холбоосон дээр дүрслэгдсэн.

![[Perceptron with bias.png]]

Perceptron-ны тэгшитгэлийг хялбарчилж өөр хэлбэрт бичье. Хялбарчлахын тулд тухайн оролт бүрт бодогдон  гарч буй нийлбэр нь 0-ээс их байх үед 1, эсрэг тохиолдолд 0-ийг гаргах хэсгийг нэг функц болгоё. Энэ функцыг $h(x)$ гээд шинээр бичвэл:

$$
y = h(b + w_1x_1 + w_2x_2)
$$
$$
h(x) = \begin{cases}
    0 & (x \leq 0) \\
    1 & (x > 0)
\end{cases}
$$
Эхний тэгшитгэл нь оролтын дохионуудын нийлбэрийг  $h(x)$ гэдэг функцт оруулж буцааж буй утгыг нь $y$-т авч байгааг илэрхийлнэ. Дараагийн тэгшитгэл нь $h(x)$ гэдэг функц нь оролт нь эерэг үед 1-ийг буцааж, сөрөг үед 0-ийг буцаадаг функц гэдгийг харуулж байна.

### 活性化関数の登場 (Activation function)

Дээр дурдсан $h(x)$ шиг оролтын дохионуудын нийлбэрийг хүлээн авч гаралтын дохионд хувиргадаг функцуудыг **Идэвхжүүлэх функц (Activation function)** гэдэг.
Энэ функц дохионуудын нийлбэрийг хэр зэрэг идэвжүүлэх вэ? Өөрөөр хэр зэрэг 1 гэсэн дохиог цааш дамжуулах вэ? гэдгийг шийдвэрлэх үүрэгтэй.

Илүү цэвэрхэн ойлгомжтойгоор бичвэл:

$$a = b + w_1x_1 + w_2x_2$$
$$y=h(a)$$
болно.
Зургаар харуулвал
![[Perceptron with activation function.png]]