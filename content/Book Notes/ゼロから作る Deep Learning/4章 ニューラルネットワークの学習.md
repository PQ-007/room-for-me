Одоо жинхэнэ сургалтын (жин, bias-аа өгөгдлүүдээсээ автоматаар тохируулах) хэсэг рүүгээ орно. Энэхүү сургалтыг явуулахын тулд **алдааны функц (loss function)** гэдэг зүйл оруулж ирдэг. Энэ алдагдлын функцдээ тулгуурлан жин, bias зэрэг параметруудад байж болох хамгийн бага утгыг олж өгөх нь энэ сургалтын гол зорилго. Байж болох хамгийн бага утгыг олох арга болгож **gradient-ын арга** гэдэг функцийн налууг ашигладаг аргыг судлана.

## データから学習する

### データ駆動

機械学習はデータが命です。データから答えを探し、データからパターンを見つ
け、データからストーリーを語る――これが機械学習で行うことであり、データがな
ければ何も始まりません。

ディープラーニングは、「end-to-end machine learning」と呼ばれること
があります。ここで言う end-to-end とは、「端から端まで」という意味であ
り、これは生データ（入力）から目的の結果（出力）を得ることを意味します。

Ердөөсөө Deep learning-ийн давуу тал нь тоо таних байна уу? нохой таних байна уу? хамаагүй дата нь байхад нөгөө параметруудаа тохируудаад нэг л  алгоритмаар тухайн асуудлыг шийдчихэд болдогт байгаа. Хүний нэмэлт чиглүүлгэ эдэр шаардлагагүй.
### 訓練データとテストデータ

За ер нь сургалт хийхэд шаардлагатай дата бол 2 төрөл бий. Яг сураад сайжраад явахад зориулсан дата, тэгээд тест хийж хэр сайжирснаа шалгах зориулалттай дата. Яагаад ингэж 2 хувааж байна вэ? гэхлээр сургалтын бус дата дээр, ерөнхий тохиолдолд манай модел хэрхэн ажиллаж буйг дүгнэх, тэгээд сайжруулаад ерөнхий тохиолдолд дажгүй ажилчихдаг модел гаргаж авах нь машин сургалтын туйлын зорилго юм.

Тэгээд ер нь бол олон төрлийн эх сурвалжтай их дата ашиглах хэрэгтэй. Ганц төрлийн цөөхөн дата дээр сургавал тэр л датан дундаа ажилдаг моделтой хоцроно. Энийг 過学
習（overfitting）гэдэг. Олон төрлийн дата ашиглаж үүнээс зайлхийх хэрэгтэй.

## 損失関数

За манай машин сургалтанд нэг индекс тоо буюу одоо гол үзүүлэлтийг маань харуулах тоо байдаг. Энийгээ ашиглаад л параметрүүдээ янз бүр болгож засна. Үүнийг нь 損失関数（loss function) гэж нэрлэдэг.

Ер дурын функцээ ашиглаж болох ч ихэвчлэн айхтар нэртэй энэ 2-ыг 一般には、2 乗和誤差や交差エントロピー誤差 гэх мэтээр бас шалгарсан хэдэн функ байдаг эдгээрийг нь ашигладаг.

### 2 乗和誤差

